{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDeequ\n",
    "\n",
    "+ Original Post: <https://aws.amazon.com/pt/blogs/big-data/test-data-quality-at-scale-with-deequ/>\n",
    "+ Data Set: <s3://amazon-reviews-pds/parquet/product_category=Electronics/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = spark.read.parquet(\"s3://amazon-reviews-pds/parquet/product_category=Electronics/\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>51163966</td>\n",
       "      <td>R2RX7KLOQQ5VBG</td>\n",
       "      <td>B00000JBAT</td>\n",
       "      <td>738692522</td>\n",
       "      <td>Diamond Rio Digital Player</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Why just 30 minutes?</td>\n",
       "      <td>RIO is really great, but Diamond should increa...</td>\n",
       "      <td>1999-06-22</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30050581</td>\n",
       "      <td>RPHMRNCGZF2HN</td>\n",
       "      <td>B001BRPLZU</td>\n",
       "      <td>197287809</td>\n",
       "      <td>NG 283220 AC Adapter Power Supply for HP Pavil...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great quality for the price!!!!</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52246039</td>\n",
       "      <td>R3PD79H9CTER8U</td>\n",
       "      <td>B00000JBAT</td>\n",
       "      <td>738692522</td>\n",
       "      <td>Diamond Rio Digital Player</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>The digital audio &amp;quot;killer app&amp;quot;</td>\n",
       "      <td>One of several first-generation portable MP3 p...</td>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>16186332</td>\n",
       "      <td>R3U6UVNH7HGDMS</td>\n",
       "      <td>B009CY43DK</td>\n",
       "      <td>856142222</td>\n",
       "      <td>HDE Mini Portable Capsule Travel Mobile Pocket...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>I like it, got some for the Grandchilren</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>53068431</td>\n",
       "      <td>R3SP31LN235GV3</td>\n",
       "      <td>B00000JBSN</td>\n",
       "      <td>670078724</td>\n",
       "      <td>JVC FS-7000 Executive MicroSystem (Discontinue...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Design flaws ruined the better functions</td>\n",
       "      <td>I returned mine for a couple of reasons:  The ...</td>\n",
       "      <td>1999-07-13</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>23604361</td>\n",
       "      <td>R1IYAZPPTRJF7E</td>\n",
       "      <td>B005LQ83EI</td>\n",
       "      <td>503838146</td>\n",
       "      <td>BlueRigger High Speed HDMI Cable with Ethernet...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Never got around to returning the 1 out of 2 ...</td>\n",
       "      <td>Never got around to returning the 1 out of 2 t...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>52036200</td>\n",
       "      <td>RDYOBX7A6YZ2X</td>\n",
       "      <td>B00000JHYS</td>\n",
       "      <td>738692522</td>\n",
       "      <td>Rio PMP 300 Special-Edition MP3 Player</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Might want to wait.</td>\n",
       "      <td>I really like the Rio.  doesn't skip, light we...</td>\n",
       "      <td>1999-07-16</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>12029527</td>\n",
       "      <td>R3RDD9FILG1LSN</td>\n",
       "      <td>B00CVB12RG</td>\n",
       "      <td>587294791</td>\n",
       "      <td>Brookstone 2.4GHz Wireless TV Headphones</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Saved my. marriage, I swear to god.</td>\n",
       "      <td>Saved my.marriage, I swear to god.</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>51618361</td>\n",
       "      <td>R31I45LN3W8UUM</td>\n",
       "      <td>B00000J1SI</td>\n",
       "      <td>505031276</td>\n",
       "      <td>GPX C3860 Portable CD Player with 22-Track Pro...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>LOW PRICE GOOD VALUE</td>\n",
       "      <td>Very Good Product, good enough if you're tight...</td>\n",
       "      <td>1999-07-17</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>12246316</td>\n",
       "      <td>R2RVEE19EN94YK</td>\n",
       "      <td>B00JAYS824</td>\n",
       "      <td>995064901</td>\n",
       "      <td>ABLEGRID Trademarked Car Adapter For Cradlepoi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>thanks to this i have my own personal mobile c...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace customer_id       review_id  product_id product_parent  \\\n",
       "0          US    51163966  R2RX7KLOQQ5VBG  B00000JBAT      738692522   \n",
       "1          US    30050581   RPHMRNCGZF2HN  B001BRPLZU      197287809   \n",
       "2          US    52246039  R3PD79H9CTER8U  B00000JBAT      738692522   \n",
       "3          US    16186332  R3U6UVNH7HGDMS  B009CY43DK      856142222   \n",
       "4          US    53068431  R3SP31LN235GV3  B00000JBSN      670078724   \n",
       "5          US    23604361  R1IYAZPPTRJF7E  B005LQ83EI      503838146   \n",
       "6          US    52036200   RDYOBX7A6YZ2X  B00000JHYS      738692522   \n",
       "7          US    12029527  R3RDD9FILG1LSN  B00CVB12RG      587294791   \n",
       "8          US    51618361  R31I45LN3W8UUM  B00000J1SI      505031276   \n",
       "9          US    12246316  R2RVEE19EN94YK  B00JAYS824      995064901   \n",
       "\n",
       "                                       product_title  star_rating  \\\n",
       "0                         Diamond Rio Digital Player            3   \n",
       "1  NG 283220 AC Adapter Power Supply for HP Pavil...            5   \n",
       "2                         Diamond Rio Digital Player            5   \n",
       "3  HDE Mini Portable Capsule Travel Mobile Pocket...            5   \n",
       "4  JVC FS-7000 Executive MicroSystem (Discontinue...            3   \n",
       "5  BlueRigger High Speed HDMI Cable with Ethernet...            3   \n",
       "6             Rio PMP 300 Special-Edition MP3 Player            4   \n",
       "7           Brookstone 2.4GHz Wireless TV Headphones            5   \n",
       "8  GPX C3860 Portable CD Player with 22-Track Pro...            5   \n",
       "9  ABLEGRID Trademarked Car Adapter For Cradlepoi...            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              0            0    N                 N   \n",
       "1              0            0    N                 Y   \n",
       "2              1            2    N                 N   \n",
       "3              0            0    N                 Y   \n",
       "4              5            5    N                 N   \n",
       "5              0            0    N                 Y   \n",
       "6              0            0    N                 N   \n",
       "7              3            3    N                 Y   \n",
       "8              8            9    N                 N   \n",
       "9              0            0    N                 Y   \n",
       "\n",
       "                                    review_headline  \\\n",
       "0                              Why just 30 minutes?   \n",
       "1                                        Five Stars   \n",
       "2          The digital audio &quot;killer app&quot;   \n",
       "3                                        Five Stars   \n",
       "4          Design flaws ruined the better functions   \n",
       "5  Never got around to returning the 1 out of 2 ...   \n",
       "6                               Might want to wait.   \n",
       "7               Saved my. marriage, I swear to god.   \n",
       "8                              LOW PRICE GOOD VALUE   \n",
       "9                                        Five Stars   \n",
       "\n",
       "                                         review_body review_date  year  \n",
       "0  RIO is really great, but Diamond should increa...  1999-06-22  1999  \n",
       "1                    Great quality for the price!!!!  2014-11-17  2014  \n",
       "2  One of several first-generation portable MP3 p...  1999-06-30  1999  \n",
       "3           I like it, got some for the Grandchilren  2014-11-17  2014  \n",
       "4  I returned mine for a couple of reasons:  The ...  1999-07-13  1999  \n",
       "5  Never got around to returning the 1 out of 2 t...  2014-11-17  2014  \n",
       "6  I really like the Rio.  doesn't skip, light we...  1999-07-16  1999  \n",
       "7                 Saved my.marriage, I swear to god.  2014-11-17  2014  \n",
       "8  Very Good Product, good enough if you're tight...  1999-07-17  1999  \n",
       "9  thanks to this i have my own personal mobile c...  2014-11-17  2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydeequ.analyzers import AnalyzerContext\n",
    "from pydeequ.analyzers import AnalysisRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ApproxCountDistinct**: Approximate number of distinct value, computed with HyperLogLogPlusPlus sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------------+---------+\n",
      "|entity|instance   |name               |value    |\n",
      "+------+-----------+-------------------+---------+\n",
      "|Column|customer_id|ApproxCountDistinct|2170036.0|\n",
      "|Column|product_id |ApproxCountDistinct|169835.0 |\n",
      "|Column|review_id  |ApproxCountDistinct|3010972.0|\n",
      "+------+-----------+-------------------+---------+"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import ApproxCountDistinct\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(ApproxCountDistinct(\"customer_id\"))\\\n",
    "                                          .addAnalyzer(ApproxCountDistinct(\"product_id\"))\\\n",
    "                                          .addAnalyzer(ApproxCountDistinct(\"review_id\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ApproxQuantile**: Approximate quantile of a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+-----+\n",
      "|entity|instance   |name              |value|\n",
      "+------+-----------+------------------+-----+\n",
      "|Column|star_rating|ApproxQuantile-0.5|5.0  |\n",
      "+------+-----------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import ApproxQuantile\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(ApproxQuantile(\"star_rating\", quantile = 0.5))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ApproxQuantiles**: Approximate quantiles of a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------------+-----+\n",
      "|entity|instance   |name               |value|\n",
      "+------+-----------+-------------------+-----+\n",
      "|Column|star_rating|ApproxQuantiles-0.1|1.0  |\n",
      "|Column|star_rating|ApproxQuantiles-0.5|5.0  |\n",
      "|Column|star_rating|ApproxQuantiles-0.9|5.0  |\n",
      "+------+-----------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import ApproxQuantiles\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(ApproxQuantiles(\"star_rating\", quantiles = [0.1, 0.5, 0.9]))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Completeness**: Fraction of non-null values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------+-----+\n",
      "|entity|instance |name        |value|\n",
      "+------+---------+------------+-----+\n",
      "|Column|review_id|Completeness|1.0  |\n",
      "+------+---------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Completeness\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Completeness(\"review_id\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compliance**: Fraction of rows that comply with the given column constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+------------------+\n",
      "|entity|instance       |name      |value             |\n",
      "+------+---------------+----------+------------------+\n",
      "|Column|top star_rating|Compliance|0.7494070692849394|\n",
      "+------+---------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Compliance\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Compliance(\"top star_rating\", \"star_rating >= 4.0\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation**: Pearson correlation coefficient, measures the linear correlation between two columns. The result is in the range [-1, 1], where 1 means positive linear correlation, -1 means negative linear correlation, and 0 means no correlation.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+-----------+--------------------+\n",
      "|entity     |instance               |name       |value               |\n",
      "+-----------+-----------------------+-----------+--------------------+\n",
      "|Mutlicolumn|total_votes,star_rating|Correlation|-0.03451097996538765|\n",
      "+-----------+-----------------------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Correlation\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Correlation(\"total_votes\", \"star_rating\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountDistinct**: Number of distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------------+---------+\n",
      "|entity|instance |name         |value    |\n",
      "+------+---------+-------------+---------+\n",
      "|Column|review_id|CountDistinct|3109479.0|\n",
      "+------+---------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import CountDistinct\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(CountDistinct(\"review_id\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataType**: Distribution of data types such as Boolean, Fractional, Integral, and String. The resulting histogram allows filtering by relative or absolute fractions.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------------+---------+\n",
      "|entity|instance|name                      |value    |\n",
      "+------+--------+--------------------------+---------+\n",
      "|Column|year    |Histogram.bins            |5.0      |\n",
      "|Column|year    |Histogram.abs.Boolean     |0.0      |\n",
      "|Column|year    |Histogram.ratio.Boolean   |0.0      |\n",
      "|Column|year    |Histogram.abs.Fractional  |0.0      |\n",
      "|Column|year    |Histogram.ratio.Fractional|0.0      |\n",
      "|Column|year    |Histogram.abs.Integral    |3120938.0|\n",
      "|Column|year    |Histogram.ratio.Integral  |1.0      |\n",
      "|Column|year    |Histogram.abs.Unknown     |0.0      |\n",
      "|Column|year    |Histogram.ratio.Unknown   |0.0      |\n",
      "|Column|year    |Histogram.abs.String      |0.0      |\n",
      "|Column|year    |Histogram.ratio.String    |0.0      |\n",
      "+------+--------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import DataType\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(DataType(\"year\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distinctness**: Fraction of distinct values of a column over the number of all values of a column. Distinct values occur at least once. Example: [a, a, b] contains two distinct values a and b, so distinctness is 2/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------+------------------+\n",
      "|entity|instance |name        |value             |\n",
      "+------+---------+------------+------------------+\n",
      "|Column|review_id|Distinctness|0.9963283474391352|\n",
      "+------+---------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Distinctness\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Distinctness(\"review_id\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy**: Entropy is a measure of the level of information contained in an event (value in a column) when considering all possible events (values in a column). It is measured in nats (natural units of information). Entropy is estimated using observed value counts as the negative sum of (value_count/total_count) * log(value_count/total_count). Example: [a, b, b, c, c] has three distinct values with counts [1, 2, 2]. Entropy is then (-1/5*log(1/5)-2/5*log(2/5)-2/5*log(2/5)) = 1.055."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+------------------+\n",
      "|entity|instance   |name   |value             |\n",
      "+------+-----------+-------+------------------+\n",
      "|Column|star_rating|Entropy|1.2339328231223723|\n",
      "+------+-----------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Entropy\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Entropy(\"star_rating\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum**: Maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+-----+\n",
      "|entity|instance   |name   |value|\n",
      "+------+-----------+-------+-----+\n",
      "|Column|star_rating|Maximum|5.0  |\n",
      "+------+-----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Maximum\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Maximum(\"star_rating\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean**: Mean value; null values are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----+-----------------+\n",
      "|entity|instance   |name|value            |\n",
      "+------+-----------+----+-----------------+\n",
      "|Column|star_rating|Mean|4.036143941340712|\n",
      "+------+-----------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Mean\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Mean(\"star_rating\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimum**: Minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+-----+\n",
      "|entity|instance   |name   |value|\n",
      "+------+-----------+-------+-----+\n",
      "|Column|star_rating|Minimum|1.0  |\n",
      "+------+-----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Minimum\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Minimum(\"star_rating\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MutualInformation**: Mutual information describes how much information about one column (one random variable) can be inferred from another column (another random variable). If the two columns are independent, mutual information is zero. If one column is a function of the other column, mutual information is the entropy of the column. Mutual information is symmetric and nonnegative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+-----------------+--------------------+\n",
      "|entity     |instance               |name             |value               |\n",
      "+-----------+-----------------------+-----------------+--------------------+\n",
      "|Mutlicolumn|total_votes,star_rating|MutualInformation|0.023555225905757905|\n",
      "+-----------+-----------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import MutualInformation\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(MutualInformation([\"total_votes\", \"star_rating\"]))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PatternMatch**: Fraction of rows that comply with a given regular experssion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------+-----+\n",
      "|entity|instance   |name        |value|\n",
      "+------+-----------+------------+-----+\n",
      "|Column|marketplace|PatternMatch|0.0  |\n",
      "+------+-----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import PatternMatch\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(PatternMatch(\"marketplace\", pattern_regex=r\"\\w{2}\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size**: Number of rows in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+---------+\n",
      "|entity |instance|name|value    |\n",
      "+-------+--------+----+---------+\n",
      "|Dataset|*       |Size|3120938.0|\n",
      "+-------+--------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Size\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Size())\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sum**: Sum of all values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----+---------+\n",
      "|entity|instance   |name|value    |\n",
      "+------+-----------+----+---------+\n",
      "|Column|total_votes|Sum |7427283.0|\n",
      "+------+-----------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Sum\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Sum(\"total_votes\"))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UniqueValueRatio**: Fraction of unique values over the number of all distinct values of a column. Unique values occur exactly once; distinct values occur at least once. Example: [a, a, b] contains one unique value b, and two distinct values a and b, so the unique value ratio is 1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------------+-----+\n",
      "|entity|instance   |name            |value|\n",
      "+------+-----------+----------------+-----+\n",
      "|Column|star_rating|UniqueValueRatio|0.0  |\n",
      "+------+-----------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import UniqueValueRatio\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(UniqueValueRatio([\"star_rating\"]))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniqueness**: Fraction of unique values over the number of all values of a column. Unique values occur exactly once. Example: [a, a, b] contains one unique value b, so uniqueness is 1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-----+\n",
      "|entity|instance   |name      |value|\n",
      "+------+-----------+----------+-----+\n",
      "|Column|star_rating|Uniqueness|0.0  |\n",
      "+------+-----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import Uniqueness\n",
    "AnalyzerContext.successMetricsAsDataFrame(spark,AnalysisRunner(spark)\\\n",
    "                                          .onData(df)\\\n",
    "                                          .addAnalyzer(Uniqueness([\"star_rating\"]))\\\n",
    "                                          .run())\\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Check\n",
    "For writing tests on data, we start with the VerificationSuite and add Checks on attributes of the data\n",
    "> Every scala check are available um python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.checks import Check\n",
    "from pydeequ.checks import CheckLevel\n",
    "from pydeequ.verification import VerificationSuite\n",
    "from pydeequ.verification import VerificationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Callback Server Starting\n",
      "INFO:Socket listening on ('127.0.0.1', 25334)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Callback server started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Callback Connection ready to receive messages\n",
      "INFO:Received command c on object id p0\n",
      "INFO:Received command c on object id p1\n",
      "INFO:Received command c on object id p2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>check_level</th>\n",
       "      <th>check_status</th>\n",
       "      <th>constraint</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>constraint_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>SizeConstraint(Size(None))</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>MinimumConstraint(Minimum(star_rating,None))</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>MaximumConstraint(Maximum(star_rating,None))</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_id,...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>UniquenessConstraint(Uniqueness(List(review_id...</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.9926566948782706 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>CompletenessConstraint(Completeness(marketplac...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>ComplianceConstraint(Compliance(marketplace co...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>ComplianceConstraint(Compliance(year is non-ne...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          check check_level check_status  \\\n",
       "0  Review Check       Error        Error   \n",
       "1  Review Check       Error        Error   \n",
       "2  Review Check       Error        Error   \n",
       "3  Review Check       Error        Error   \n",
       "4  Review Check       Error        Error   \n",
       "5  Review Check       Error        Error   \n",
       "6  Review Check       Error        Error   \n",
       "7  Review Check       Error        Error   \n",
       "\n",
       "                                          constraint constraint_status  \\\n",
       "0                         SizeConstraint(Size(None))           Success   \n",
       "1       MinimumConstraint(Minimum(star_rating,None))           Success   \n",
       "2       MaximumConstraint(Maximum(star_rating,None))           Success   \n",
       "3  CompletenessConstraint(Completeness(review_id,...           Success   \n",
       "4  UniquenessConstraint(Uniqueness(List(review_id...           Failure   \n",
       "5  CompletenessConstraint(Completeness(marketplac...           Success   \n",
       "6  ComplianceConstraint(Compliance(marketplace co...           Success   \n",
       "7  ComplianceConstraint(Compliance(year is non-ne...           Success   \n",
       "\n",
       "                                  constraint_message  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Value: 0.9926566948782706 does not meet the co...  \n",
       "5                                                     \n",
       "6                                                     \n",
       "7                                                     "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = Check(spark, CheckLevel.Error, \"Review Check\")\n",
    "\n",
    "checkResult = VerificationSuite(spark).onData(df).addCheck(check\\\n",
    "                                                           .hasSize(lambda x: x >= 300000)\n",
    "                                                           .hasMin(\"star_rating\", lambda x: x == 1.0)\n",
    "                                                           .hasMax(\"star_rating\", lambda x: x == 5.0)\n",
    "                                                           .isComplete(\"review_id\")\n",
    "                                                           .isUnique(\"review_id\")\n",
    "                                                           .isComplete(\"marketplace\")\n",
    "                                                           .isContainedIn(\"marketplace\", [\"US\", \"UK\", \"DE\", \"JP\", \"FR\"])\n",
    "                                                           .isNonNegative(\"year\") \n",
    "                                                          ).run()\n",
    "    \n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.suggestions import ConstraintSuggestionRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Received command  on object id \n",
      "INFO:Closing down callback connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplianceConstraint(Compliance('star_rating' ...</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'star_rating' has value range '5', '4', '1', '...</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "      <td>If we see a categorical range for a column, we...</td>\n",
       "      <td>.isContainedIn(\"star_rating\", [\"5\", \"4\", \"1\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplianceConstraint(Compliance('year' has val...</td>\n",
       "      <td>year</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'year' has value range '2014', '2015', '2013',...</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "      <td>If we see a categorical range for a column, we...</td>\n",
       "      <td>.isContainedIn(\"year\", [\"2014\", \"2015\", \"2013\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplianceConstraint(Compliance('vine' has val...</td>\n",
       "      <td>vine</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'vine' has value range 'N', 'Y'</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "      <td>If we see a categorical range for a column, we...</td>\n",
       "      <td>.isContainedIn(\"vine\", [\"N\", \"Y\"])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplianceConstraint(Compliance('marketplace' ...</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'marketplace' has value range 'US', 'UK', 'DE'...</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "      <td>If we see a categorical range for a column, we...</td>\n",
       "      <td>.isContainedIn(\"marketplace\", [\"US\", \"UK\", \"DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplianceConstraint(Compliance('verified_purc...</td>\n",
       "      <td>verified_purchase</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'verified_purchase' has value range 'Y', 'N'</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "      <td>If we see a categorical range for a column, we...</td>\n",
       "      <td>.isContainedIn(\"verified_purchase\", [\"Y\", \"N\"])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name        column_name  \\\n",
       "0  ComplianceConstraint(Compliance('star_rating' ...        star_rating   \n",
       "1  ComplianceConstraint(Compliance('year' has val...               year   \n",
       "2  ComplianceConstraint(Compliance('vine' has val...               vine   \n",
       "3  ComplianceConstraint(Compliance('marketplace' ...        marketplace   \n",
       "4  ComplianceConstraint(Compliance('verified_purc...  verified_purchase   \n",
       "\n",
       "   current_value                                        description  \\\n",
       "0  Compliance: 1  'star_rating' has value range '5', '4', '1', '...   \n",
       "1  Compliance: 1  'year' has value range '2014', '2015', '2013',...   \n",
       "2  Compliance: 1                    'vine' has value range 'N', 'Y'   \n",
       "3  Compliance: 1  'marketplace' has value range 'US', 'UK', 'DE'...   \n",
       "4  Compliance: 1       'verified_purchase' has value range 'Y', 'N'   \n",
       "\n",
       "          suggesting_rule                                   rule_description  \\\n",
       "0  CategoricalRangeRule()  If we see a categorical range for a column, we...   \n",
       "1  CategoricalRangeRule()  If we see a categorical range for a column, we...   \n",
       "2  CategoricalRangeRule()  If we see a categorical range for a column, we...   \n",
       "3  CategoricalRangeRule()  If we see a categorical range for a column, we...   \n",
       "4  CategoricalRangeRule()  If we see a categorical range for a column, we...   \n",
       "\n",
       "                                 code_for_constraint  \n",
       "0  .isContainedIn(\"star_rating\", [\"5\", \"4\", \"1\", ...  \n",
       "1  .isContainedIn(\"year\", [\"2014\", \"2015\", \"2013\"...  \n",
       "2                 .isContainedIn(\"vine\", [\"N\", \"Y\"])  \n",
       "3  .isContainedIn(\"marketplace\", [\"US\", \"UK\", \"DE...  \n",
       "4    .isContainedIn(\"verified_purchase\", [\"Y\", \"N\"])  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import CategoricalRangeRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(CategoricalRangeRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CompletenessConstraint(Completeness(review_id,...</td>\n",
       "      <td>review_id</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'review_id' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"review_id\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CompletenessConstraint(Completeness(customer_i...</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'customer_id' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"customer_id\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompletenessConstraint(Completeness(review_dat...</td>\n",
       "      <td>review_date</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'review_date' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"review_date\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CompletenessConstraint(Completeness(helpful_vo...</td>\n",
       "      <td>helpful_votes</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'helpful_votes' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"helpful_votes\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CompletenessConstraint(Completeness(star_ratin...</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'star_rating' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"star_rating\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CompletenessConstraint(Completeness(year,None))</td>\n",
       "      <td>year</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'year' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"year\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CompletenessConstraint(Completeness(product_ti...</td>\n",
       "      <td>product_title</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_title' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"product_title\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CompletenessConstraint(Completeness(product_id...</td>\n",
       "      <td>product_id</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_id' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"product_id\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CompletenessConstraint(Completeness(total_vote...</td>\n",
       "      <td>total_votes</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'total_votes' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"total_votes\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CompletenessConstraint(Completeness(product_pa...</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_parent' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"product_parent\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CompletenessConstraint(Completeness(vine,None))</td>\n",
       "      <td>vine</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'vine' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"vine\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CompletenessConstraint(Completeness(marketplac...</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'marketplace' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"marketplace\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CompletenessConstraint(Completeness(verified_p...</td>\n",
       "      <td>verified_purchase</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'verified_purchase' is not null</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "      <td>If a column is complete in the sample, we sugg...</td>\n",
       "      <td>.isComplete(\"verified_purchase\")</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      constraint_name        column_name  \\\n",
       "0   CompletenessConstraint(Completeness(review_id,...          review_id   \n",
       "1   CompletenessConstraint(Completeness(customer_i...        customer_id   \n",
       "2   CompletenessConstraint(Completeness(review_dat...        review_date   \n",
       "3   CompletenessConstraint(Completeness(helpful_vo...      helpful_votes   \n",
       "4   CompletenessConstraint(Completeness(star_ratin...        star_rating   \n",
       "5     CompletenessConstraint(Completeness(year,None))               year   \n",
       "6   CompletenessConstraint(Completeness(product_ti...      product_title   \n",
       "7   CompletenessConstraint(Completeness(product_id...         product_id   \n",
       "8   CompletenessConstraint(Completeness(total_vote...        total_votes   \n",
       "9   CompletenessConstraint(Completeness(product_pa...     product_parent   \n",
       "10    CompletenessConstraint(Completeness(vine,None))               vine   \n",
       "11  CompletenessConstraint(Completeness(marketplac...        marketplace   \n",
       "12  CompletenessConstraint(Completeness(verified_p...  verified_purchase   \n",
       "\n",
       "        current_value                      description  \\\n",
       "0   Completeness: 1.0          'review_id' is not null   \n",
       "1   Completeness: 1.0        'customer_id' is not null   \n",
       "2   Completeness: 1.0        'review_date' is not null   \n",
       "3   Completeness: 1.0      'helpful_votes' is not null   \n",
       "4   Completeness: 1.0        'star_rating' is not null   \n",
       "5   Completeness: 1.0               'year' is not null   \n",
       "6   Completeness: 1.0      'product_title' is not null   \n",
       "7   Completeness: 1.0         'product_id' is not null   \n",
       "8   Completeness: 1.0        'total_votes' is not null   \n",
       "9   Completeness: 1.0     'product_parent' is not null   \n",
       "10  Completeness: 1.0               'vine' is not null   \n",
       "11  Completeness: 1.0        'marketplace' is not null   \n",
       "12  Completeness: 1.0  'verified_purchase' is not null   \n",
       "\n",
       "             suggesting_rule  \\\n",
       "0   CompleteIfCompleteRule()   \n",
       "1   CompleteIfCompleteRule()   \n",
       "2   CompleteIfCompleteRule()   \n",
       "3   CompleteIfCompleteRule()   \n",
       "4   CompleteIfCompleteRule()   \n",
       "5   CompleteIfCompleteRule()   \n",
       "6   CompleteIfCompleteRule()   \n",
       "7   CompleteIfCompleteRule()   \n",
       "8   CompleteIfCompleteRule()   \n",
       "9   CompleteIfCompleteRule()   \n",
       "10  CompleteIfCompleteRule()   \n",
       "11  CompleteIfCompleteRule()   \n",
       "12  CompleteIfCompleteRule()   \n",
       "\n",
       "                                     rule_description  \\\n",
       "0   If a column is complete in the sample, we sugg...   \n",
       "1   If a column is complete in the sample, we sugg...   \n",
       "2   If a column is complete in the sample, we sugg...   \n",
       "3   If a column is complete in the sample, we sugg...   \n",
       "4   If a column is complete in the sample, we sugg...   \n",
       "5   If a column is complete in the sample, we sugg...   \n",
       "6   If a column is complete in the sample, we sugg...   \n",
       "7   If a column is complete in the sample, we sugg...   \n",
       "8   If a column is complete in the sample, we sugg...   \n",
       "9   If a column is complete in the sample, we sugg...   \n",
       "10  If a column is complete in the sample, we sugg...   \n",
       "11  If a column is complete in the sample, we sugg...   \n",
       "12  If a column is complete in the sample, we sugg...   \n",
       "\n",
       "                 code_for_constraint  \n",
       "0           .isComplete(\"review_id\")  \n",
       "1         .isComplete(\"customer_id\")  \n",
       "2         .isComplete(\"review_date\")  \n",
       "3       .isComplete(\"helpful_votes\")  \n",
       "4         .isComplete(\"star_rating\")  \n",
       "5                .isComplete(\"year\")  \n",
       "6       .isComplete(\"product_title\")  \n",
       "7          .isComplete(\"product_id\")  \n",
       "8         .isComplete(\"total_votes\")  \n",
       "9      .isComplete(\"product_parent\")  \n",
       "10               .isComplete(\"vine\")  \n",
       "11        .isComplete(\"marketplace\")  \n",
       "12  .isComplete(\"verified_purchase\")  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import CompleteIfCompleteRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(CompleteIfCompleteRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplianceConstraint(Compliance('marketplace' ...</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>Compliance: 0.9949982985884372</td>\n",
       "      <td>'marketplace' has value range 'US' for at leas...</td>\n",
       "      <td>FractionalCategoricalRangeRule(0.9)</td>\n",
       "      <td>If we see a categorical range for most values ...</td>\n",
       "      <td>.isContainedIn(\"marketplace\", [\"US\"], lambda x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplianceConstraint(Compliance('vine' has val...</td>\n",
       "      <td>vine</td>\n",
       "      <td>Compliance: 0.9939271462617969</td>\n",
       "      <td>'vine' has value range 'N' for at least 99.0% ...</td>\n",
       "      <td>FractionalCategoricalRangeRule(0.9)</td>\n",
       "      <td>If we see a categorical range for most values ...</td>\n",
       "      <td>.isContainedIn(\"vine\", [\"N\"], lambda x: x &gt;= 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplianceConstraint(Compliance('year' has val...</td>\n",
       "      <td>year</td>\n",
       "      <td>Compliance: 0.9286063997426415</td>\n",
       "      <td>'year' has value range '2014', '2015', '2013',...</td>\n",
       "      <td>FractionalCategoricalRangeRule(0.9)</td>\n",
       "      <td>If we see a categorical range for most values ...</td>\n",
       "      <td>.isContainedIn(\"year\", [\"2014\", \"2015\", \"2013\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplianceConstraint(Compliance('star_rating' ...</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Compliance: 0.942110993553861</td>\n",
       "      <td>'star_rating' has value range '5', '4', '1', '...</td>\n",
       "      <td>FractionalCategoricalRangeRule(0.9)</td>\n",
       "      <td>If we see a categorical range for most values ...</td>\n",
       "      <td>.isContainedIn(\"star_rating\", [\"5\", \"4\", \"1\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name  column_name  \\\n",
       "0  ComplianceConstraint(Compliance('marketplace' ...  marketplace   \n",
       "1  ComplianceConstraint(Compliance('vine' has val...         vine   \n",
       "2  ComplianceConstraint(Compliance('year' has val...         year   \n",
       "3  ComplianceConstraint(Compliance('star_rating' ...  star_rating   \n",
       "\n",
       "                    current_value  \\\n",
       "0  Compliance: 0.9949982985884372   \n",
       "1  Compliance: 0.9939271462617969   \n",
       "2  Compliance: 0.9286063997426415   \n",
       "3   Compliance: 0.942110993553861   \n",
       "\n",
       "                                         description  \\\n",
       "0  'marketplace' has value range 'US' for at leas...   \n",
       "1  'vine' has value range 'N' for at least 99.0% ...   \n",
       "2  'year' has value range '2014', '2015', '2013',...   \n",
       "3  'star_rating' has value range '5', '4', '1', '...   \n",
       "\n",
       "                       suggesting_rule  \\\n",
       "0  FractionalCategoricalRangeRule(0.9)   \n",
       "1  FractionalCategoricalRangeRule(0.9)   \n",
       "2  FractionalCategoricalRangeRule(0.9)   \n",
       "3  FractionalCategoricalRangeRule(0.9)   \n",
       "\n",
       "                                    rule_description  \\\n",
       "0  If we see a categorical range for most values ...   \n",
       "1  If we see a categorical range for most values ...   \n",
       "2  If we see a categorical range for most values ...   \n",
       "3  If we see a categorical range for most values ...   \n",
       "\n",
       "                                 code_for_constraint  \n",
       "0  .isContainedIn(\"marketplace\", [\"US\"], lambda x...  \n",
       "1  .isContainedIn(\"vine\", [\"N\"], lambda x: x >= 0...  \n",
       "2  .isContainedIn(\"year\", [\"2014\", \"2015\", \"2013\"...  \n",
       "3  .isContainedIn(\"star_rating\", [\"5\", \"4\", \"1\", ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import FractionalCategoricalRangeRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(FractionalCategoricalRangeRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplianceConstraint(Compliance('customer_id' ...</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>Minimum: 10005.0</td>\n",
       "      <td>'customer_id' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"customer_id\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplianceConstraint(Compliance('helpful_votes...</td>\n",
       "      <td>helpful_votes</td>\n",
       "      <td>Minimum: 0.0</td>\n",
       "      <td>'helpful_votes' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"helpful_votes\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplianceConstraint(Compliance('star_rating' ...</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Minimum: 1.0</td>\n",
       "      <td>'star_rating' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"star_rating\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplianceConstraint(Compliance('year' has no ...</td>\n",
       "      <td>year</td>\n",
       "      <td>Minimum: 1999.0</td>\n",
       "      <td>'year' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"year\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplianceConstraint(Compliance('total_votes' ...</td>\n",
       "      <td>total_votes</td>\n",
       "      <td>Minimum: 0.0</td>\n",
       "      <td>'total_votes' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"total_votes\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ComplianceConstraint(Compliance('product_paren...</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>Minimum: 6478.0</td>\n",
       "      <td>'product_parent' has no negative values</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "      <td>If we see only non-negative numbers in a colum...</td>\n",
       "      <td>.isNonNegative(\"product_parent\")</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name     column_name  \\\n",
       "0  ComplianceConstraint(Compliance('customer_id' ...     customer_id   \n",
       "1  ComplianceConstraint(Compliance('helpful_votes...   helpful_votes   \n",
       "2  ComplianceConstraint(Compliance('star_rating' ...     star_rating   \n",
       "3  ComplianceConstraint(Compliance('year' has no ...            year   \n",
       "4  ComplianceConstraint(Compliance('total_votes' ...     total_votes   \n",
       "5  ComplianceConstraint(Compliance('product_paren...  product_parent   \n",
       "\n",
       "      current_value                              description  \\\n",
       "0  Minimum: 10005.0     'customer_id' has no negative values   \n",
       "1      Minimum: 0.0   'helpful_votes' has no negative values   \n",
       "2      Minimum: 1.0     'star_rating' has no negative values   \n",
       "3   Minimum: 1999.0            'year' has no negative values   \n",
       "4      Minimum: 0.0     'total_votes' has no negative values   \n",
       "5   Minimum: 6478.0  'product_parent' has no negative values   \n",
       "\n",
       "            suggesting_rule  \\\n",
       "0  NonNegativeNumbersRule()   \n",
       "1  NonNegativeNumbersRule()   \n",
       "2  NonNegativeNumbersRule()   \n",
       "3  NonNegativeNumbersRule()   \n",
       "4  NonNegativeNumbersRule()   \n",
       "5  NonNegativeNumbersRule()   \n",
       "\n",
       "                                    rule_description  \\\n",
       "0  If we see only non-negative numbers in a colum...   \n",
       "1  If we see only non-negative numbers in a colum...   \n",
       "2  If we see only non-negative numbers in a colum...   \n",
       "3  If we see only non-negative numbers in a colum...   \n",
       "4  If we see only non-negative numbers in a colum...   \n",
       "5  If we see only non-negative numbers in a colum...   \n",
       "\n",
       "                code_for_constraint  \n",
       "0     .isNonNegative(\"customer_id\")  \n",
       "1   .isNonNegative(\"helpful_votes\")  \n",
       "2     .isNonNegative(\"star_rating\")  \n",
       "3            .isNonNegative(\"year\")  \n",
       "4     .isNonNegative(\"total_votes\")  \n",
       "5  .isNonNegative(\"product_parent\")  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import NonNegativeNumbersRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(NonNegativeNumbersRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CompletenessConstraint(Completeness(review_hea...</td>\n",
       "      <td>review_headline</td>\n",
       "      <td>Completeness: 0.9999987183340393</td>\n",
       "      <td>'review_headline' has less than 1% missing values</td>\n",
       "      <td>RetainCompletenessRule()</td>\n",
       "      <td>If a column is incomplete in the sample, we mo...</td>\n",
       "      <td>.hasCompleteness(\"review_headline\", lambda x: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CompletenessConstraint(Completeness(review_bod...</td>\n",
       "      <td>review_body</td>\n",
       "      <td>Completeness: 0.9999724441818453</td>\n",
       "      <td>'review_body' has less than 1% missing values</td>\n",
       "      <td>RetainCompletenessRule()</td>\n",
       "      <td>If a column is incomplete in the sample, we mo...</td>\n",
       "      <td>.hasCompleteness(\"review_body\", lambda x: x &gt;=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name      column_name  \\\n",
       "0  CompletenessConstraint(Completeness(review_hea...  review_headline   \n",
       "1  CompletenessConstraint(Completeness(review_bod...      review_body   \n",
       "\n",
       "                      current_value  \\\n",
       "0  Completeness: 0.9999987183340393   \n",
       "1  Completeness: 0.9999724441818453   \n",
       "\n",
       "                                         description  \\\n",
       "0  'review_headline' has less than 1% missing values   \n",
       "1      'review_body' has less than 1% missing values   \n",
       "\n",
       "            suggesting_rule  \\\n",
       "0  RetainCompletenessRule()   \n",
       "1  RetainCompletenessRule()   \n",
       "\n",
       "                                    rule_description  \\\n",
       "0  If a column is incomplete in the sample, we mo...   \n",
       "1  If a column is incomplete in the sample, we mo...   \n",
       "\n",
       "                                 code_for_constraint  \n",
       "0  .hasCompleteness(\"review_headline\", lambda x: ...  \n",
       "1  .hasCompleteness(\"review_body\", lambda x: x >=...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import RetainCompletenessRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(RetainCompletenessRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnalysisBasedConstraint(DataType(customer_id,N...</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>DataType: Integral</td>\n",
       "      <td>'customer_id' has type Integral</td>\n",
       "      <td>RetainTypeRule()</td>\n",
       "      <td>If we detect a non-string type, we suggest a t...</td>\n",
       "      <td>.hasDataType(\"customer_id\", ConstrainableDataT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnalysisBasedConstraint(DataType(product_paren...</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>DataType: Integral</td>\n",
       "      <td>'product_parent' has type Integral</td>\n",
       "      <td>RetainTypeRule()</td>\n",
       "      <td>If we detect a non-string type, we suggest a t...</td>\n",
       "      <td>.hasDataType(\"product_parent\", ConstrainableDa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name     column_name  \\\n",
       "0  AnalysisBasedConstraint(DataType(customer_id,N...     customer_id   \n",
       "1  AnalysisBasedConstraint(DataType(product_paren...  product_parent   \n",
       "\n",
       "        current_value                         description   suggesting_rule  \\\n",
       "0  DataType: Integral     'customer_id' has type Integral  RetainTypeRule()   \n",
       "1  DataType: Integral  'product_parent' has type Integral  RetainTypeRule()   \n",
       "\n",
       "                                    rule_description  \\\n",
       "0  If we detect a non-string type, we suggest a t...   \n",
       "1  If we detect a non-string type, we suggest a t...   \n",
       "\n",
       "                                 code_for_constraint  \n",
       "0  .hasDataType(\"customer_id\", ConstrainableDataT...  \n",
       "1  .hasDataType(\"product_parent\", ConstrainableDa...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import RetainTypeRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(RetainTypeRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>code_for_constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UniquenessConstraint(Uniqueness(List(review_id...</td>\n",
       "      <td>review_id</td>\n",
       "      <td>ApproxDistinctness: 0.9647650802419017</td>\n",
       "      <td>'review_id' is unique</td>\n",
       "      <td>UniqueIfApproximatelyUniqueRule()</td>\n",
       "      <td>If the ratio of approximate num distinct value...</td>\n",
       "      <td>.isUnique(\"review_id\")</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     constraint_name column_name  \\\n",
       "0  UniquenessConstraint(Uniqueness(List(review_id...   review_id   \n",
       "\n",
       "                            current_value            description  \\\n",
       "0  ApproxDistinctness: 0.9647650802419017  'review_id' is unique   \n",
       "\n",
       "                     suggesting_rule  \\\n",
       "0  UniqueIfApproximatelyUniqueRule()   \n",
       "\n",
       "                                    rule_description     code_for_constraint  \n",
       "0  If the ratio of approximate num distinct value...  .isUnique(\"review_id\")  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.suggestions import UniqueIfApproximatelyUniqueRule\n",
    "pd.DataFrame(ConstraintSuggestionRunner(spark).onData(df)\\\n",
    "             .addConstraintRule(UniqueIfApproximatelyUniqueRule()\n",
    ").run()['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.repository import InMemoryMetricsRepository\n",
    "from pydeequ.repository import ResultKey\n",
    "from pydeequ.verification import VerificationSuite\n",
    "from pydeequ.verification import RelativeRateOfChangeStrategy\n",
    "from pyspark.sql import Row\n",
    "\n",
    "metricsRepository = InMemoryMetricsRepository(spark)\n",
    "tags = {'tag': 'pydeequ anomaly check'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+----+---+\n",
      "|key|   value|                desc|prop|var|\n",
      "+---+--------+--------------------+----+---+\n",
      "|  1|Thingy A|      awesome thing.|high|  0|\n",
      "|  2|Thingy B|available at http...|null|  0|\n",
      "+---+--------+--------------------+----+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check_status</th>\n",
       "      <th>check_level</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>check</th>\n",
       "      <th>constraint_message</th>\n",
       "      <th>constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Success</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Success</td>\n",
       "      <td>Anomaly check for Size(None)</td>\n",
       "      <td></td>\n",
       "      <td>AnomalyConstraint(Size(None))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  check_status check_level constraint_status                         check  \\\n",
       "0      Success     Warning           Success  Anomaly check for Size(None)   \n",
       "\n",
       "  constraint_message                     constraint  \n",
       "0                     AnomalyConstraint(Size(None))  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesterdaysDF  = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        Row(key=1, value=\"Thingy A\", desc=\"awesome thing.\", prop=\"high\", var=0),\n",
    "        Row(key=2, value=\"Thingy B\", desc=\"available at http://thingb.com\", prop=None, var=0)\n",
    "    ]).toDF()\n",
    "\n",
    "yesterdaysDF.show()\n",
    "pd.DataFrame(\n",
    "    VerificationSuite(spark) \\\n",
    "        .onData(yesterdaysDF) \\\n",
    "        .useRepository(metricsRepository)\\\n",
    "        .saveOrAppendResult(\n",
    "            ResultKey(spark, ResultKey.current_milli_time() - 24 * 60 * 1000, tags)\n",
    "        )\\\n",
    "        .addAnomalyCheck(\n",
    "            RelativeRateOfChangeStrategy(maxRateIncrease=2.0),Size()) \\\n",
    "        .run()\\\n",
    "    .checkResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+----+---+\n",
      "|key|   value|                desc|prop|var|\n",
      "+---+--------+--------------------+----+---+\n",
      "|  1|Thingy A|      awesome thing.|high|  0|\n",
      "|  2|Thingy B|available at http...|null|  0|\n",
      "|  3|    null|                null| low|  5|\n",
      "|  4|Thingy D|checkout https://...| low| 10|\n",
      "|  5|Thingy E|                null|high| 12|\n",
      "+---+--------+--------------------+----+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check_status</th>\n",
       "      <th>check_level</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>check</th>\n",
       "      <th>constraint_message</th>\n",
       "      <th>constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Anomaly check for Size(None)</td>\n",
       "      <td>Value: 5.0 does not meet the constraint requir...</td>\n",
       "      <td>AnomalyConstraint(Size(None))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  check_status check_level constraint_status                         check  \\\n",
       "0      Warning     Warning           Failure  Anomaly check for Size(None)   \n",
       "\n",
       "                                  constraint_message  \\\n",
       "0  Value: 5.0 does not meet the constraint requir...   \n",
       "\n",
       "                      constraint  \n",
       "0  AnomalyConstraint(Size(None))  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todaysDF  = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        Row(key=1, value=\"Thingy A\", desc=\"awesome thing.\"                  , prop=\"high\", var=0),\n",
    "        Row(key=2, value=\"Thingy B\", desc=\"available at http://thingb.com\"  , prop=None  , var=0),\n",
    "        Row(key=3, value=None      , desc=None                              , prop=\"low\" , var=5),\n",
    "        Row(key=4, value=\"Thingy D\", desc=\"checkout https://thingd.ca\"      , prop=\"low\" , var=10),\n",
    "        Row(key=5, value=\"Thingy E\", desc=None                              , prop=\"high\", var=12),\n",
    "    ]).toDF()\n",
    "\n",
    "todaysDF.show()\n",
    "pd.DataFrame(\n",
    "    VerificationSuite(spark) \\\n",
    "        .onData(todaysDF) \\\n",
    "        .useRepository(metricsRepository)\\\n",
    "        .saveOrAppendResult(\n",
    "            ResultKey(spark, ResultKey.current_milli_time(), tags)\n",
    "        )\\\n",
    "        .addAnomalyCheck(\n",
    "            RelativeRateOfChangeStrategy(maxRateIncrease=2.0),Size()) \\\n",
    "        .run()\\\n",
    "    .checkResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+--------+----+-----+-------+-------+-----+-------+-----+---+----+------+\n",
      "|age|  sex| cp|trestbps|chol|  fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
      "+---+-----+---+--------+----+-----+-------+-------+-----+-------+-----+---+----+------+\n",
      "| 37| true|  2|     130| 250|false|   true|    187|false|    3.5|    0|  0|   2|  true|\n",
      "| 39| true|  2|     140| 321|false|  false|    182|false|    0.0|    2|  0|   2|  true|\n",
      "| 34| true|  3|     118| 182|false|  false|    174|false|    0.0|    2|  0|   2|  true|\n",
      "| 35|false|  0|     138| 183|false|   true|    182|false|    1.4|    2|  0|   2|  true|\n",
      "| 29| true|  1|     130| 204|false|  false|    202|false|    0.0|    2|  0|   2|  true|\n",
      "| 37|false|  2|     120| 215|false|   true|    170|false|    0.0|    2|  0|   2|  true|\n",
      "| 39|false|  2|      94| 199|false|   true|    179|false|    0.0|    2|  0|   2|  true|\n",
      "| 34|false|  1|     118| 210|false|   true|    192|false|    0.7|    2|  0|   2|  true|\n",
      "| 39|false|  2|     138| 220|false|   true|    152|false|    0.0|    1|  0|   2|  true|\n",
      "| 35| true|  1|     122| 192|false|   true|    174|false|    0.0|    2|  0|   2|  true|\n",
      "| 38| true|  2|     138| 175|false|   true|    173|false|    0.0|    2|  4|   2|  true|\n",
      "| 38| true|  2|     138| 175|false|   true|    173|false|    0.0|    2|  4|   2|  true|\n",
      "| 39| true|  0|     118| 219|false|   true|    140|false|    1.2|    1|  0|   3| false|\n",
      "| 35| true|  0|     120| 198|false|   true|    130| true|    1.6|    1|  0|   3| false|\n",
      "| 35| true|  0|     126| 282|false|  false|    156| true|    0.0|    2|  0|   3| false|\n",
      "| 38| true|  3|     120| 231|false|   true|    182| true|    3.8|    1|  0|   3| false|\n",
      "+---+-----+---+--------+----+-----+-------+-------+-----+-------+-----+---+----+------+\n",
      "\n",
      "<pydeequ.profiles.ColumnProfilesBuilder object at 0x7faab0fce9e8>"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pydeequ.profiles import ColumnProfilerRunner\n",
    "df = spark.read.parquet(\"s3://compasso-raw/hearts_pqt/\")\n",
    "df.show()\n",
    "result = ColumnProfilerRunner(spark).onData(df).run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "rows = list()\n",
    "for col, profile in result.profiles.items():\n",
    "    rows.append(        \n",
    "        dict(column=profile.column,\n",
    "            distincts=profile.approximateNumDistinctValues,\n",
    "            completeness=profile.completeness,\n",
    "            dataType=profile.dataType,\n",
    "            isInferred=profile.isDataTypeInferred,\n",
    "            ts=datetime.now()\n",
    "        )\n",
    "    )\n",
    "pdf = pd.DataFrame(rows)\n",
    "pdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------+----------+---------+----------+--------------------+\n",
      "|index|  column|completeness|  dataType|distincts|isInferred|                  ts|\n",
      "+-----+--------+------------+----------+---------+----------+--------------------+\n",
      "|    0| oldpeak|         1.0|Fractional|        7|     false|2021-05-28 10:52:...|\n",
      "|    1|trestbps|         1.0|  Integral|        8|     false|2021-05-28 10:52:...|\n",
      "|    2|      ca|         1.0|  Integral|        2|     false|2021-05-28 10:52:...|\n",
      "|    3|    thal|         1.0|  Integral|        2|     false|2021-05-28 10:52:...|\n",
      "|    4|     fbs|         1.0|   Boolean|        1|     false|2021-05-28 10:52:...|\n",
      "|    5|     age|         1.0|  Integral|        6|     false|2021-05-28 10:52:...|\n",
      "|    6|     sex|         1.0|   Boolean|        2|     false|2021-05-28 10:52:...|\n",
      "|    7| restecg|         1.0|   Boolean|        2|     false|2021-05-28 10:52:...|\n",
      "|    8|  target|         1.0|   Boolean|        2|     false|2021-05-28 10:52:...|\n",
      "|    9|    chol|         1.0|  Integral|       14|     false|2021-05-28 10:52:...|\n",
      "|   10|   exang|         1.0|   Boolean|        2|     false|2021-05-28 10:52:...|\n",
      "|   11|      cp|         1.0|  Integral|        4|     false|2021-05-28 10:52:...|\n",
      "|   12| thalach|         1.0|  Integral|       12|     false|2021-05-28 10:52:...|\n",
      "|   13|   slope|         1.0|  Integral|        3|     false|2021-05-28 10:52:...|\n",
      "+-----+--------+------------+----------+---------+----------+--------------------+"
     ]
    }
   ],
   "source": [
    "profile_df = spark.createDataFrame(pdf)\n",
    "profile_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Hudi Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tableName = \"tb_profile\"\n",
    "basePath = f\"s3://compasso-raw/hudi/{tableName}\"\n",
    "\n",
    "hudi_options = {\n",
    "  'hoodie.table.name': tableName,\n",
    "  'hoodie.datasource.write.recordkey.field': 'index',\n",
    "  'hoodie.datasource.write.partitionpath.field': 'partitionpath',\n",
    "  'hoodie.datasource.write.table.name': tableName,\n",
    "  'hoodie.datasource.write.operation': 'upsert',\n",
    "  'hoodie.datasource.write.precombine.field': 'ts',\n",
    "  'hoodie.upsert.shuffle.parallelism': 2, \n",
    "  'hoodie.insert.shuffle.parallelism': 2\n",
    "}\n",
    "\n",
    "profile_df.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
